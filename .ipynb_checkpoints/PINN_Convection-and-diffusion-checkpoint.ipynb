{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7894df82",
   "metadata": {},
   "source": [
    "## 1 Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fee192",
   "metadata": {},
   "source": [
    "### 1.1 Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchsummary import summary\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f67f9",
   "metadata": {},
   "source": [
    "### 1.2 Connect to machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db739bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fbddde",
   "metadata": {},
   "source": [
    "## 2 Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f692269",
   "metadata": {},
   "source": [
    "### 2.1 Generate training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(N):\n",
    "    global x\n",
    "    x = torch.zeros([N, N, 2]).to(device)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            x[i][j][0] = i; # x\n",
    "            x[i][j][1] = j; # y\n",
    "    x.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2f678",
   "metadata": {},
   "source": [
    "### 2.2 Generate benchmark solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ef7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FD(N, Pe, w, tol = 1e-6):\n",
    "    global Tn\n",
    "    Tn = np.zeros((N, N))\n",
    "    Tn[:, N - 1] = 1\n",
    "    Tn[0, :] = 1\n",
    "    \n",
    "    h = 1 / (N - 1)\n",
    "    iteration = 0\n",
    "    res = 1\n",
    "    \n",
    "#     tol = h^4*0.01\n",
    "    print(\"tol: \", tol)\n",
    "    \n",
    "    while(res > tol):\n",
    "        iteration = iteration + 1\n",
    "        res = 0\n",
    "        for i in range(1, N - 1):\n",
    "            for j in range(1, N - 1):\n",
    "                prev = Tn[i, j]\n",
    "                Tn[i, j] = Tn[i + 1 , j] + Tn[i - 1, j] + Tn[i, j + 1] + Tn[i, j - 1]\n",
    "                Tn[i, j] = Tn[i, j] - 1 * Pe * (Tn[i + 1 , j] - Tn[i - 1, j] + Tn[i, j + 1] - Tn[i, j - 1]) * 0.5\n",
    "                Tn[i, j] = Tn[i, j] * 0.25\n",
    "                res = max(res, np.abs((Tn[i, j] - prev) / (prev + 1e-20))) \n",
    "                Tn[i, j] = prev + w * (Tn[i, j] - prev)\n",
    "            \n",
    "        print(\"iteration: \", iteration, \"res: \", res)\n",
    "        \n",
    "    plt.subplots()[1].set_box_aspect(1)\n",
    "    plt.contourf(np.transpose(Tn), vmax = Tn.max(), vmin = Tn.min(), levels = 20) #gnd_truth, PINN_out, error               \n",
    "    plt.colorbar()\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(17,5))\n",
    "    ax.plot(np.linspace(0, N - 1, N), Tn[int((N-1)/2), :], '-o')\n",
    "    ax.set(xlim=(0, N))\n",
    "    ax.set_box_aspect(1)\n",
    "    plt.xlabel('j')\n",
    "    plt.ylabel('T')\n",
    "    plt.legend(['FDM', 'PINN'])\n",
    "    plt.xlim((0,N-1))\n",
    "    plt.ylim((0, 1))\n",
    "    \n",
    "    return Tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4859c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Special case: Pe = inf\n",
    "def gnd_Peinf(N):\n",
    "    global Tn\n",
    "    Tn = np.zeros((N, N))\n",
    "    Tn[:, N - 1] = 1\n",
    "    Tn[0, :] = 1\n",
    "    for j in range(1, N - 1):\n",
    "        Tn[j, j] = 0.5\n",
    "        for i in range(1, j):\n",
    "            Tn[i, j] = 1\n",
    "           \n",
    "    plt.subplots()[1].set_box_aspect(1)\n",
    "    plt.contourf(np.transpose(Tn), vmax = Tn.max(), vmin = Tn.min(), levels = 20) #gnd_truth, PINN_out, error               \n",
    "    plt.colorbar()\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(17,5))\n",
    "    ax.plot(np.linspace(0, N - 1, N), Tn[int((N-1)/2), :], '-o')\n",
    "    ax.set(xlim=(0, N))\n",
    "    ax.set_box_aspect(1)\n",
    "    plt.xlabel('j')\n",
    "    plt.ylabel('T')\n",
    "    plt.legend(['FDM', 'PINN'])\n",
    "    plt.xlim((0,N-1))\n",
    "    plt.ylim((0, 1))     \n",
    "    return Tn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db5184",
   "metadata": {},
   "source": [
    "### 2.3 PINN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a21814",
   "metadata": {},
   "source": [
    "##### Variables on the focus:\n",
    "+ N(mesh number).\n",
    "+ DAB(\"d\"imension \"a\"nalysis \"b\"ased, i.e weighing scheme):\n",
    "    0. loss weight: same weight | matrix: MSE\n",
    "    1. loss weight: weighted by dimension analyzed result | matrix: MSE\n",
    "    2. loss weight: weighted by root of dimension analyzed result | matrix: MSE\n",
    "    3. loss weight: weighted by dimension analyzed result($Pe = \\infty$) | matrix: MSE\n",
    "    4. loss weight: weighted by root of dimension analyzed result($Pe = \\infty$) | matrix: MSE\n",
    "    5. loss weight: same weight | matrix: MAE\n",
    "    6. loss weight: weighted by dimension analyzed result | matrix: MAE\n",
    "    7. loss weight: weighted by root of dimension analyzed result | matrix: MAE\n",
    "    8. loss weight: weighted by dimension analyzed result($Pe = \\infty$) | matrix: MAE\n",
    "    9. loss weight: weighted by root of dimension analyzed result($Pe = \\infty$) | matrix: MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d3a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_NN(N, Pe, Gamma = 1, w_DE = 1, w_BC = 1, DAB = 0, start_epoch = 0, train_epoch = 50000, pl = 64):\n",
    "    class Net(torch.nn.Module):\n",
    "        def __init__(self, n_feature, n_hidden, n_hidden1, n_hidden2, n_hidden3, n_output):\n",
    "            super(Net, self).__init__()\n",
    "            self.hidden = torch.nn.Linear(n_feature, n_hidden)\n",
    "            self.hidden1 = torch.nn.Linear(n_hidden, n_hidden1)\n",
    "            self.hidden2 = torch.nn.Linear(n_hidden1, n_hidden2)\n",
    "            self.hidden3 = torch.nn.Linear(n_hidden2, n_hidden3)\n",
    "            self.predict = torch.nn.Linear(n_hidden3, n_output)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.sin(self.hidden(x))\n",
    "            x = torch.sin(self.hidden1(x))\n",
    "            x = torch.sin(self.hidden2(x))\n",
    "            x = torch.sin(self.hidden3(x))\n",
    "            x = self.predict(x)\n",
    "            return x\n",
    " \n",
    "    pl_1 = 64\n",
    "    net = Net(n_feature=2, n_hidden=pl, n_hidden1=pl_1, n_hidden2=pl_1, n_hidden3=pl_1, n_output=1)     # define the network\n",
    "    net.to(device)\n",
    "    summary(net, (1,1, 2))\n",
    "\n",
    "    ########\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "    \n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    \n",
    "    if (DAB == 5)|(DAB == 6)|(DAB == 7)|(DAB == 8)|(DAB == 9):\n",
    "        loss_func = torch.nn.L1Loss()\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.8)\n",
    "    plt.ion()\n",
    "\n",
    "    ########\n",
    "\n",
    "    if(start_epoch == 0):\n",
    "        loss_epoch=[]\n",
    "        loss_values = []\n",
    "        loss_DE_values = []\n",
    "        loss_DBC_values = []\n",
    "\n",
    "    h = 1 / (N - 1)\n",
    "    loss_op = 'mean'\n",
    "\n",
    "\n",
    "    ###############################################################\n",
    "    # Define loss weight                                          #\n",
    "    ###############################################################\n",
    "\n",
    "    if DAB == 0: #MSE(1)\n",
    "        b = w_DE\n",
    "        a = w_BC\n",
    "    elif DAB == 1: #MSE(DA)\n",
    "        b = w_DE /((N-1)*(N-1)*(N-1)*(N-1) * Pe * Pe)\n",
    "        a = w_BC \n",
    "    elif DAB == 2: #MSE(Weak)\n",
    "        b = w_DE /((N-1)*(N-1)*Pe)\n",
    "        a = w_BC \n",
    "    elif DAB == 3: #MSE(DA)(inf)\n",
    "        b = w_DE /((N-1)*(N-1))\n",
    "        a = w_BC \n",
    "    elif DAB == 4: #MSE(weak)(inf)\n",
    "        b = w_DE /(N-1)\n",
    "        a = w_BC \n",
    "    elif DAB == 5: #MAE(1)\n",
    "        b = w_DE #/((N-1))\n",
    "        a = w_BC #/ 1\n",
    "    elif DAB == 6: #MAE(DA)\n",
    "        b = w_DE /((N-1)*(N-1)*Pe)\n",
    "        a = w_BC \n",
    "    elif DAB == 7: #MAE(Weak)\n",
    "        b = w_DE /((N-1)*(Pe**0.5))\n",
    "        a = w_BC \n",
    "    elif DAB == 8: #MAE(DA)(inf)\n",
    "        b = w_DE /((N-1))\n",
    "        a = w_BC \n",
    "    elif DAB == 9: #MAE(Weak)(inf)\n",
    "        b = w_DE /((N-1)**0.5)\n",
    "        a = w_BC \n",
    "        \n",
    "    ###############################################################\n",
    "    # Loss weight normalization                                   #\n",
    "    ###############################################################\n",
    "    \n",
    "    print(b, a)\n",
    "    \n",
    "    lambda_DE = b / (a + b)\n",
    "    lambda_DBC = a / (a + b)\n",
    "\n",
    "\n",
    "    ###############################################################\n",
    "    # Training                                                    #\n",
    "    ###############################################################\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    for t in range(start_epoch, train_epoch):\n",
    "        scheduler.step()\n",
    "        T_out = net(x)\n",
    "        T = T_out[:, :, 0]\n",
    "\n",
    "\n",
    "        lap_T = (-4 * T[1:-1, 1:-1] + T[2:, 1:-1] + T[:-2, 1:-1] + T[1:-1, 2:] + T[1:-1, :-2]) / (h * h)\n",
    "        Tx = (T[2:, :] - T[:-2, :])/ (h * 2) #cds\n",
    "        Ty = (T[:, 2:] - T[:, :-2])/ (h * 2) #cds\n",
    "    #     Tx = (T[1:-1, :] - T[:-2, :])/ (h) #up\n",
    "    #     Ty = (T[:, 1:-1] - T[:, :-2])/ (h) #up\n",
    "        \n",
    "        if (Gamma != 0):\n",
    "            loss_DE = loss_func(lap_T , (Tx[:, 1:-1] + Ty[1:-1, :]) * Pe / h)\n",
    "        elif(Gamma == 0): #Pe = inf\n",
    "            loss_DE = loss_func(lap_T * 0 , (Tx[:, 1:-1] + Ty[1:-1, :]))\n",
    "            \n",
    "        loss_DBC = loss_func(T[:, 0], torch.zeros((N , 1)).to(device)) #s\n",
    "        loss_DBC = loss_DBC + loss_func(T[:, -1] - 1, torch.zeros((N , 1)).to(device)) #n\n",
    "        loss_DBC = loss_DBC + loss_func(T[0, :] - 1, torch.zeros((1 , N)).to(device)) #w\n",
    "        loss_DBC = loss_DBC + loss_func(T[-1, :], torch.zeros((1 , N)).to(device)) #e\n",
    "\n",
    "        loss =  lambda_DE * loss_DE + lambda_DBC * loss_DBC\n",
    "\n",
    "        loss_epoch.append(t)\n",
    "        loss_DE_values.append(loss_DE.item())\n",
    "        loss_DBC_values.append(loss_DBC.item())\n",
    "        loss_values.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    #####\n",
    "    \n",
    "    print(\"Epoch: \", t, \" ,loss: \", loss)\n",
    "    plt.subplots()[1].set_box_aspect(1)  \n",
    "    plt.cla()\n",
    "    plt.contourf(np.transpose(torch.reshape(T, (N, N)).cpu().detach().numpy()), vmax = Tn.max(), vmin = Tn.min(), levels = 20)\n",
    "    plt.colorbar()\n",
    "    plt.pause(0.1)\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    print(\"Loss curve: \")\n",
    "    plt.plot(loss_epoch, loss_values, loss_epoch, loss_DE_values, loss_epoch, loss_DBC_values)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['$\\mathcal{L}$', '$\\mathcal{L}_{DE}$','$\\mathcal{L}_{DBC}$'])\n",
    "    plt.semilogy()\n",
    "    plt.pause(0.1)\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    print(\"Error: \")\n",
    "    plt.subplots()[1].set_box_aspect(1)  \n",
    "    plt.cla()\n",
    "    plt.contourf(np.transpose(torch.reshape(T, (N, N)).cpu().detach().numpy() - Tn), vmax = Tn.max(), vmin = Tn.min(), levels = 20)\n",
    "    plt.colorbar()\n",
    "    plt.pause(0.1)\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    print(\"x = 0.5: \")\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(17,5))\n",
    "    plot_x = np.linspace(0, N - 1, N)\n",
    "    if Gamma == 0:\n",
    "        ana = np.zeros(N)\n",
    "        ana[-int(N/2):] = np.ones(int(N/2))\n",
    "        ana[-int(N/2)] = 0.5\n",
    "        ax.plot(plot_x, ana, plot_x, T[int((N-1)/2), :].cpu().detach().numpy(), 'r--')\n",
    "    elif Gamma != 0:\n",
    "        ax.plot(plot_x, np.transpose(Tn[int((N-1)/2), :]), plot_x, T[int((N-1)/2), :].cpu().detach().numpy(), 'r--')\n",
    "    \n",
    "    ax.set(xlim=(0, N - 1))\n",
    "    ax.set_box_aspect(1)\n",
    "    plt.xlabel('j')\n",
    "    plt.ylabel('T')\n",
    "    plt.legend(['Ground truth', 'PINN'])\n",
    "    plt.pause(0.1)\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    pred = Tn\n",
    "    exact = torch.reshape(T, (N, N)).cpu().detach().numpy()\n",
    "    mse = np.mean(np.power((pred - exact), 2))\n",
    "    \n",
    "    pred_1 = Tn[int((N-1)/2),:]\n",
    "    exact_1 = torch.reshape(T, (N, N)).cpu().detach().numpy()[int((N-1)/2),:]\n",
    "    mse_1 = np.mean(np.power((pred_1 - exact_1), 2))\n",
    "\n",
    "    print(f\" ||||| {loss.item() :.4} | {loss_DE.item() :.4} | {loss_DBC.item() :.4} | {time.perf_counter() - start :.2f} sec | {mse :.4} | {mse_1 :.4} |\")\n",
    "    \n",
    "    return (torch.reshape(T, (N, N)).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9188885d",
   "metadata": {},
   "source": [
    "### 2.4 Post process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f73a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotmid(Tn = np.zeros((11, 11)), T1 = np.zeros((11, 11)), T2 = np.zeros((11, 11)), Tx = np.zeros((51, 51)), N = 11, Gamma = 1):\n",
    "    print(\"x = 0.5: \")\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    plot_x = np.linspace(0, 1, N)\n",
    "    if Gamma == 0:\n",
    "        ana = np.zeros(N)\n",
    "        ana[-int(N/2):] = np.ones(int(N/2))\n",
    "        ana[int(N/2)] = 0.5\n",
    "        ax.plot(plot_x, ana, '-k', markerfacecolor='none')\n",
    "        ax.plot(plot_x, T1[int((N-1)/2), :], 'sr', ms = 10, markerfacecolor='none')\n",
    "        ax.plot(plot_x, T2[int((N-1)/2), :], '^b', ms = 10, markerfacecolor='none')\n",
    "        ax.plot(plot_x, Tx[int((N-1)/2), :], '+g', ms = 10, markerfacecolor='none')\n",
    "        plt.legend(['$T_{true}$', '$\\hatT_{0}$', '$\\hatT_{NM}$', '${\\hatT_{NM}}^2$'], fontsize=\"14\", frameon=False)\n",
    "        \n",
    "    elif Gamma != 0:\n",
    "        ax.plot(plot_x, (Tn[int((N-1)/2), :]), '-k', markerfacecolor='none')\n",
    "        ax.plot(plot_x, T1[int((N-1)/2), :], 'sr', ms = 10, markerfacecolor='none')\n",
    "        ax.plot(plot_x, T2[int((N-1)/2), :], '^b', ms = 10, markerfacecolor='none')\n",
    "        ax.plot(plot_x, Tx[int((N-1)/2), :], '+g', ms = 10, markerfacecolor='none')\n",
    "        plt.legend(['$T_{FDM}$', '$\\hatT_{0}$', '$\\hatT_{NM}$', '${\\hatT_{NM}}^2$'], fontsize=\"14\", frameon=False)\n",
    "    \n",
    "    ax.set(xlim=(0, 1))\n",
    "    ax.set_box_aspect(1)\n",
    "    plt.xlabel('y')\n",
    "    plt.ylabel('T')\n",
    "    plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b85f8d",
   "metadata": {},
   "source": [
    "## 3. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3379a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# Sample                                                      #\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pe = 100\n",
    "N = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f19e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tn = compute_FD(N, Pe, w = 0.01, tol= 1e-2) # Pe or Gamma, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785158e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "T0 = predict_NN(N, Pe, DAB = 0, train_epoch = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8743909",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = predict_NN(N, Pe, DAB = 1, train_epoch = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff55267",
   "metadata": {},
   "outputs": [],
   "source": [
    "T2 = predict_NN(N, Pe, DAB = 2, train_epoch = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b2eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotmid(Tn, T0, T1, T2, N = N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
